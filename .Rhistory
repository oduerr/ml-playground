x
}
american.woman = data.frame(matrix(ncol=2, nrow=33, c(22,131,41,139,52,128,23,128,41,171,54,105,24,116,46,137,56,145,27,106,47,111,57,141,28,114,48,115,58,153,9,123,49,133,59,157,30,117,49,128,63,155,32,122,50,183,67,176,33,99,51,130,71,172,35,121,51,133,77,178,40,147,51,144,81,217), byrow = TRUE))
colnames(american.woman) = c('age', 'sbp')
american.woman
american.woman[,1]
american.woman[,2]
american.woman
write.csv(file='~/Downloads/american.woman.csv', american.woman)
write.csv(file='~/Downloads/american.woman.csv', american.woman, row.names = FALSE)
colnames(american.woman) = c('age', 'sbp')
american.woman[1,2]
graph_from_data_frame
library(igraph)
library(ggraph)
draw_example_SCM = function(
vals = c(rep(NA,3), rnorm(3)),
doX=FALSE,
show_vals = TRUE,
min = -2,
max  = 2,
size = 20
){
node = c('Z','X','Y', 'Uz', 'Ux', 'Uy')
nodes = data.frame(
node = node,
exogeneous = c(rep(FALSE,3),rep(TRUE,3)),
vals = vals,
node_names = paste(node, round(vals,1), sep='\n')
)
if (!show_vals) nodes$node_names = node
if (doX){
rel = data.frame(
from=c('Z', 'X', 'Uz', 'Uy'),
to=c('Y', 'Y', 'Z',  'Y')
)
} else{
rel = data.frame(
from=c('Z', 'Z', 'X', 'Uz', 'Ux', 'Uy'),
to=c('X', 'Y', 'Y', 'Z', 'X', 'Y')
)
}
layout = as.matrix(
data.frame(
x = c(2,1,3,2,1,3),
y = c(2,1,1,3,2,2)
)
gig = graph_from_data_frame(rel, vertices = nodes)
print(gig, e=TRUE, v=TRUE)
#plot.igraph(gig, layout=layout)
g = ggraph(gig, layout = layout) +
geom_edge_link(colour='gray',
arrow = arrow(type = "closed", angle = 20),
end_cap = circle(1),
start_cap = circle(1),
width = 0.5, show.legend = TRUE) +
geom_node_point(aes(shape=exogeneous, col=vals), size=size, alpha = 0.5)  +
geom_node_text(aes(label = node_names)) +
#theme_graph()+
xlim(0.8,3.2)+
ylim(0.8,3.2)+
scale_color_continuous(type='viridis', limits=c(min,max), name='Values')+
#scale_color_hue()+
scale_shape(guide = 'none')
return(g)
}
american.woman = data.frame(matrix(ncol=2, nrow=33, c(22,131,41,139,52,128,23,128,41,171,54,105,24,116,46,137,56,145,27,106,47,111,57,141,28,114,48,115,58,153,9,123,49,133,59,157,30,117,49,128,63,155,32,122,50,183,67,176,33,99,51,130,71,172,35,121,51,133,77,178,40,147,51,144,81,217), byrow = TRUE))
colnames(american.woman) = c('age', 'sbp')
american.woman[1,2]
american.woman = data.frame(matrix(ncol=2, nrow=33, c(22,131,41,139,52,128,23,128,41,171,54,105,24,116,46,137,56,145,27,106,47,111,57,141,28,114,48,115,58,153,9,123,49,133,59,157,30,117,49,128,63,155,32,122,50,183,67,176,33,99,51,130,71,172,35,121,51,133,77,178,40,147,51,144,81,217), byrow = TRUE))
colnames(american.woman) = c('age', 'sbp')
head(american.woman,3)
ojs_define(aa = american.woman)
american.woman + 20
american.woman + 2000
#https://github.com/brry/rdwd
# https://bookdown.org/brry/rdwd/
library(rdwd)
library(tidyverse)
HH = selectDWD('Hamburg-Fuhlsbuettel', res='daily', var='kl', per='recent')
HH = dataDWD(HH, read = TRUE, varnames=TRUE)
HH$ort = 'HH'
KN = selectDWD('Konstanz', res='daily', var='kl', per='recent')
KN = dataDWD(KN, read = TRUE, varnames=TRUE)
KN$ort = 'KN'
df = bind_rows(KN, HH)
df %>% ggplot(aes(x=MESS_DATUM, y=SDK.Sonnenscheindauer)) +
geom_smooth(aes(col=ort))
df %>% ggplot(aes(x=MESS_DATUM, y=TXK.Lufttemperatur_Max)) +
geom_smooth(aes(col=ort)) +
geom_line(aes(col=ort))
df %>% ggplot(aes(x=MESS_DATUM, y=RSK.Niederschlagshoehe)) +
geom_smooth(aes(col=ort)) +
geom_line(aes(col=ort))
#RSK.Niederschlagshoehe in mm https://www.dwd.de/DE/leistungen/klimadatendeutschland/beschreibung_tagesmonatswerte.html
mean(HH$RSK.Niederschlagshoehe > 0.1)
mean(KN$RSK.Niederschlagshoehe > 0.1)
mean(KN$SDK.Sonnenscheindauer)
mean(HH$SDK.Sonnenscheindauer > 5)
mean(KN$SDK.Sonnenscheindauer > 5)
df$regen = df$RSK.Niederschlagshoehe > 0.1
df$sonne = !df$regen & df$SDK.Sonnenscheindauer > 5
df$be = !df$regen & !df$sonne
#df %>% select(sonne, regen ,be) %>% rowSums() all 1
library(keras)
library(tensorflow)
model <- keras_model_sequential()
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax')
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>%
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 500,
shuffle = TRUE)
plot(history)
model$evaluate(X,Y)
X = matrix(c(1,0,0), nrow = 1)
model(X) #
predict(model,X)
# Extract the weights from your neural network
W <- lapply(model$weights, as.matrix)
z = X %*% t(W[[1]])   + W[[2]][1]
p = exp(z)/sum(exp(z))
library(igraph)
# Create an edge list representing the weights
edges <- list()
for (i in 1:length(weights)) {
weight_matrix <- weights[[i]]
edge_list <- as.data.frame(cbind(row(weight_matrix), col(weight_matrix), weight_matrix))
colnames(edge_list) <- c("from", "to", "weight")
edges[[i]] <- edge_list
}
# Create a graph from the edge list
g <- graph_from_data_frame(do.call(rbind, edges[[1]]), directed = TRUE)
plot(g)
# Plot the graph, using the edge weight as the edge width
plot(g, edge.width = E(g)$weight / max(E(g)$weight) * 8, edge.curved = 0.2, vertex.size = 0)
get_weights(model)
df %>% select(sonne, regen ,be) %>% rowSums()
#df %>% select(sonne, regen ,be) %>% rowSums() all 1
library(keras)
library(tensorflow)
model <- keras_model_sequential()
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax')
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 20,
shuffle = TRUE)
plot(history)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
X = X[-nrow(X),] #Remove last row
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
#df %>% select(sonne, regen ,be) %>% rowSums() all 1
library(keras)
library(tensorflow)
model <- keras_model_sequential()
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax')
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax', use_bias = false)
model <- keras_model_sequential()
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax', use_bias = FALSE)
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
X = matrix(c(1,0,0), nrow = 1)
model(X) #
predict(model,X)
# Extract the weights from your neural network
W <- lapply(model$weights, as.matrix)
z = X %*% t(W[[1]])#   + W[[2]][1]
p = exp(z)/sum(exp(z))
p
X = matrix(c(1,0,0), nrow = 1)
X
model(X) #
predict(model,X)
# Extract the weights from your neural network
W <- lapply(model$weights, as.matrix)
z = X %*% t(W[[1]])#   + W[[2]][1]
p = exp(z)/sum(exp(z))
(p = exp(z)/sum(exp(z)))
z = X %*% W[[1]]#   + W[[2]][1]
(p = exp(z)/sum(exp(z)))
W[[1]]
#X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
X = df %>% filter(ort == 'HH') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
X = matrix(c(1,0,0), nrow = 1)
model(X) #
#df %>% select(sonne, regen ,be) %>% rowSums() all 1
library(keras)
library(tensorflow)
model <- keras_model_sequential()
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax', use_bias = FALSE)
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
#X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
X = df %>% filter(ort == 'HH') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
X = matrix(c(1,0,0), nrow = 1)
model(X) #
predict(model,X)
# Extract the weights from your neural network
W <- lapply(model$weights, as.matrix)
z = X %*% W[[1]]#   + W[[2]][1]
(p = exp(z)/sum(exp(z)))
#https://github.com/brry/rdwd
# https://bookdown.org/brry/rdwd/
library(rdwd)
library(tidyverse)
HH = selectDWD('Hamburg-Fuhlsbuettel', res='daily', var='kl', per='recent')
HH = dataDWD(HH, read = TRUE, varnames=TRUE)
HH$ort = 'HH'
KN = selectDWD('Konstanz', res='daily', var='kl', per='recent')
KN = dataDWD(KN, read = TRUE, varnames=TRUE)
KN$ort = 'KN'
df = bind_rows(KN, HH)
df %>% ggplot(aes(x=MESS_DATUM, y=SDK.Sonnenscheindauer)) +
geom_smooth(aes(col=ort))
df %>% ggplot(aes(x=MESS_DATUM, y=SDK.Sonnenscheindauer)) +
geom_smooth(aes(col=ort)) + ylim(0,9)
df %>% ggplot(aes(x=MESS_DATUM, y=TXK.Lufttemperatur_Max)) +
geom_smooth(aes(col=ort)) +
geom_line(aes(col=ort))
df %>% ggplot(aes(x=MESS_DATUM, y=RSK.Niederschlagshoehe)) +
geom_smooth(aes(col=ort)) +
geom_line(aes(col=ort))
#RSK.Niederschlagshoehe in mm https://www.dwd.de/DE/leistungen/klimadatendeutschland/beschreibung_tagesmonatswerte.html
mean(HH$RSK.Niederschlagshoehe > 0.1)
mean(KN$RSK.Niederschlagshoehe > 0.1)
mean(KN$SDK.Sonnenscheindauer)
mean(HH$SDK.Sonnenscheindauer > 5)
mean(KN$SDK.Sonnenscheindauer > 5)
df$regen = df$RSK.Niederschlagshoehe > 0.1
df$sonne = !df$regen & df$SDK.Sonnenscheindauer > 5
df$be = !df$regen & !df$sonne
#df %>% select(sonne, regen ,be) %>% rowSums() all 1
library(keras)
library(tensorflow)
model <- keras_model_sequential()
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax', use_bias = FALSE)
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
#X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
X = df %>% filter(ort == 'HH') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
X = matrix(c(1,0,0), nrow = 1)
model(X) #
predict(model,X)
summary(model)
get_weights(model)
#X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
X = df %>% filter(ort == 'HH') %>% select(sonne, regen, be)
#df %>% select(sonne, regen ,be) %>% rowSums() all 1
library(keras)
library(tensorflow)
model <- keras_model_sequential()
model %>%
layer_dense(units = 3, input_shape = 3, activation = 'softmax', use_bias = FALSE)
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
#X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
X = df %>% filter(ort == 'HH') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
X = matrix(c(1,0,0), nrow = 1)
model(X) #
predict(model,X) #HH 0.6293542 0.259009 0.1116367
# compile model and initialize weights
model %>%
compile(
optimizer = 'adam',
loss = 'categorical_crossentropy',
metrics = c('accuracy')
)
summary(model)
get_weights(model)
#X = df %>% filter(ort == 'KN') %>% select(sonne, regen, be)
X = df %>% filter(ort == 'HH') %>% select(sonne, regen, be)
head(X,2)
Y = X[-1,] #Remove first row (one day up)
head(Y,2)
X = X[-nrow(X),] #Remove last row
X = as.matrix(X)
Y = as.matrix(Y)
model(X[1:3,])
model$evaluate(X,Y)
history <- model %>% #Takes about 30sec
fit(x = X,
y = Y,
validation_split = 0.2,
verbose = 0,
epochs = 100,
shuffle = TRUE)
plot(history)
X = matrix(c(1,0,0), nrow = 1)
model(X) #
predict(model,X) #HH 0.6293542 0.259009 0.1116367
# Extract the weights from your neural network
W <- lapply(model$weights, as.matrix)
z = X %*% W[[1]]#   + W[[2]][1]
(p = exp(z)/sum(exp(z)))
library(igraph)
# Create an edge list representing the weights
edges <- list()
for (i in 1:length(weights)) {
weight_matrix <- weights[[i]]
edge_list <- as.data.frame(cbind(row(weight_matrix), col(weight_matrix), weight_matrix))
colnames(edge_list) <- c("from", "to", "weight")
edges[[i]] <- edge_list
}
# Create a graph from the edge list
g <- graph_from_data_frame(do.call(rbind, edges[[1]]), directed = TRUE)
